# 大模型训练与参数调优完整指南

## 目录
- [1. 大模型训练基础](#1-大模型训练基础)
- [2. 数据集准备](#2-数据集准备)
- [3. 参数调优方法](#3-参数调优方法)
- [4. 完整代码实现](#4-完整代码实现)
- [5. 调参技巧与推荐配置](#5-调参技巧与推荐配置)
- [6. 实战案例](#6-实战案例)

---

## 1. 大模型训练基础

### 1.1 什么是大模型训练？

**大模型训练**就是在预训练好的大模型基础上，用特定任务的数据继续训练，让模型适应新任务。

### 1.2 生活化理解：学一门新技能

#### 场景：你已经是一个经验丰富的厨师

**预训练模型（通用能力）**：
```
你已经会做各种菜：
- 中式菜系（川菜、粤菜、鲁菜...）
- 西式菜系（法餐、意餐...）
- 日式料理
- 其他各种技能

这是"通用能力"（预训练模型）
```

**参数调优（适应新任务）**：
```
场景：客户要求你做"减脂餐"

全量微调：
你重新学习所有技能：
- 重新学习所有菜系的减脂版本
- 需要大量时间（训练时间长）
- 需要大量资源（计算资源多）
- 可能忘记原来的技能（灾难性遗忘）
❌ 成本太高

参数高效微调（LoRA）：
你只学习"减脂小技巧"：
- 保留所有原有技能
- 只添加一个"减脂小本子"（少量参数）
- 做菜时参考这个小本子
- 快速学会，资源消耗少
✅ 高效！
```

### 1.3 训练类型对比

| 训练类型 | 更新参数 | 显存需求 | 训练时间 | 适用场景 |
|---------|---------|---------|---------|---------|
| **预训练** | 100% | 极高（TB级数据） | 数周-数月 | 从零开始训练 |
| **全量微调** | 100% | 高（~28GB for 7B） | 数小时-数天 | 有充足资源 |
| **LoRA微调** | 0.1-1% | 中（~12GB） | 数分钟-数小时 | 最常用 ✅ |
| **QLoRA微调** | 0.1-1% | 低（~4GB） | 数分钟-数小时 | 显存受限 ✅ |

---

## 2. 数据集准备

### 2.1 数据集是必需的

**核心要点**：
```
没有数据 = 无法训练
数据质量差 = 模型效果差
数据量不足 = 模型过拟合
```

### 2.2 不同训练的数据需求

#### 预训练数据量

```
7B 模型：
- 最小：100GB 文本
- 推荐：1TB+ 文本
- 样本数：数十亿 tokens

175B 模型（GPT-3级别）：
- 最小：1TB 文本
- 推荐：10TB+ 文本
- 样本数：数百亿 tokens
```

#### 微调数据量

```
任务特定微调：
- 最小：1,000 样本
- 推荐：10,000-100,000 样本
- 效果：10,000 样本通常足够

指令跟随（Alpaca格式）：
- 最小：1,000 指令对
- 推荐：50,000+ 指令对
```

#### LoRA/QLoRA 数据量

```
参数高效微调：
- 最小：100 样本（Few-shot）
- 推荐：1,000-10,000 样本
- 效果：通常几千样本就够

优势：
✅ 需要数据量少
✅ 训练时间短
✅ 效果接近全量微调
```

### 2.3 常见数据集格式

#### 格式1：纯文本（Pretraining）

```text
文档1的内容...
<文档分隔符>
文档2的内容...
<文档分隔符>
文档3的内容...
```

#### 格式2：JSON（指令跟随）

```json
[
    {
        "instruction": "任务描述",
        "input": "输入（可选）",
        "output": "期望输出"
    },
    {
        "instruction": "翻译成英文",
        "input": "你好",
        "output": "Hello"
    }
]
```

#### 格式3：对话格式（Chat）

```json
[
    {
        "conversations": [
            {"role": "user", "content": "你好"},
            {"role": "assistant", "content": "你好！有什么可以帮助你的吗？"}
        ]
    }
]
```

### 2.4 数据集准备代码

```python
import json
from datasets import Dataset, load_dataset
from transformers import AutoTokenizer

def prepare_instruction_dataset():
    """准备指令跟随数据集"""
    
    # 方法1：使用公开数据集（推荐）
    print("方法1：从 Hugging Face 加载...")
    try:
        dataset = load_dataset("tatsu-lab/alpaca", split="train")
        print(f"加载成功！数据集大小: {len(dataset)}")
    except:
        print("加载失败，使用自定义数据")
        dataset = None
    
    # 方法2：使用自定义数据
    if dataset is None:
        print("方法2：使用自定义数据...")
        custom_data = [
            {
                "instruction": "解释什么是 Transformer",
                "input": "",
                "output": "Transformer 是一种深度学习架构，由 Google 在 2017 年提出..."
            },
            {
                "instruction": "翻译成英文",
                "input": "你好，世界",
                "output": "Hello, World"
            },
            {
                "instruction": "总结以下文本",
                "input": "这是一段很长的文本内容，需要总结...",
                "output": "总结：..."
            },
        ]
        
        dataset = Dataset.from_list(custom_data)
        print(f"创建自定义数据集，大小: {len(dataset)}")
    
    # 保存数据集
    dataset.save_to_disk("./instruction_dataset")
    print("数据集已保存到 ./instruction_dataset")
    
    return dataset

def format_for_training(dataset, model_name="gpt2"):
    """格式化为训练格式"""
    tokenizer = AutoTokenizer.from_pretrained(model_name)
    
    if tokenizer.pad_token is None:
        tokenizer.pad_token = tokenizer.eos_token
    
    def format_instruction(example):
        """格式化指令"""
        if "instruction" in example:
            text = f"### Instruction:\n{example['instruction']}\n"
            if example.get("input"):
                text += f"### Input:\n{example['input']}\n"
            text += f"### Response:\n{example['output']}{tokenizer.eos_token}"
        else:
            text = example.get("text", "")
        
        return {"text": text}
    
    # 格式化
    formatted_dataset = dataset.map(format_instruction)
    
    # 分词
    def tokenize(examples):
        return tokenizer(
            examples["text"],
            truncation=True,
            max_length=512,
            padding="max_length",
        )
    
    tokenized_dataset = formatted_dataset.map(
        tokenize,
        batched=True,
        remove_columns=formatted_dataset.column_names,
    )
    
    return tokenized_dataset

# 使用示例
if __name__ == "__main__":
    # 1. 准备数据集
    dataset = prepare_instruction_dataset()
    
    # 2. 格式化
    train_dataset = format_for_training(dataset)
    
    # 3. 保存
    train_dataset.save_to_disk("./processed_dataset")
    print("处理完成！数据集已保存到 ./processed_dataset")
```

---

## 3. 参数调优方法

### 3.1 全量微调（Full Fine-tuning）

**概念**：更新模型的所有参数

**数学表达式（LaTeX）**：

$$\theta_{new} = \theta_{pretrained} - \alpha \nabla_\theta L(\theta)$$

**文字版本**：
```
新参数 = 预训练参数 - 学习率 × 梯度

更新所有参数
```

**代码实现**：
```python
import torch
from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments, Trainer

def full_finetune(model_name, train_dataset, output_dir="./full_finetune_model"):
    """全量微调"""
    
    # 1. 加载模型
    model = AutoModelForCausalLM.from_pretrained(model_name)
    tokenizer = AutoTokenizer.from_pretrained(model_name)
    
    # 2. 所有参数都需要梯度
    for param in model.parameters():
        param.requires_grad = True
    
    # 3. 训练参数
    training_args = TrainingArguments(
        output_dir=output_dir,
        num_train_epochs=3,
        per_device_train_batch_size=2,  # 小 batch，因为显存需求大
        gradient_accumulation_steps=8,   # 梯度累积
        learning_rate=2e-5,              # 全量微调需要更小的学习率
        warmup_steps=100,
        logging_steps=10,
        save_steps=500,
        fp16=True,                        # 混合精度训练
        save_total_limit=2,
    )
    
    # 4. 训练
    trainer = Trainer(
        model=model,
        args=training_args,
        train_dataset=train_dataset,
    )
    
    trainer.train()
    
    # 5. 保存
    model.save_pretrained(output_dir)
    tokenizer.save_pretrained(output_dir)
    
    return model, tokenizer

# 使用
# model, tokenizer = full_finetune("gpt2", train_dataset)
```

**优缺点**：
```
优点：
✅ 效果最好（理论上）

缺点：
❌ 需要大量显存（7B模型需要约28GB）
❌ 训练时间长
❌ 可能灾难性遗忘
❌ 成本高
```

---

### 3.2 LoRA（Low-Rank Adaptation）⭐ 最流行

**核心思想**：只训练少量低秩矩阵，不更新原始参数

**数学原理**：

**数学表达式（LaTeX）**：

$$\Delta W = BA$$

其中：
- 原始权重：$W \in \mathbb{R}^{d \times k}$
- 低秩分解：$B \in \mathbb{R}^{d \times r}$，$A \in \mathbb{R}^{r \times k}$
- $r \ll \min(d, k)$（秩很小，如 4、8、16）

**前向传播**：

$$h = Wx + \Delta Wx = Wx + BAx$$

**文字版本**：
```
新权重 = 原始权重 + 低秩矩阵（B × A）

只训练 B 和 A 两个小矩阵
原始权重 W 冻结不变
```

**完整代码实现**：
```python
import torch
import torch.nn as nn
from transformers import AutoModelForCausalLM, AutoTokenizer
from transformers import TrainingArguments, Trainer
from peft import LoraConfig, get_peft_model, TaskType

def lora_finetune(
    model_name="gpt2",
    train_dataset=None,
    rank=8,
    alpha=16,
    dropout=0.1,
    learning_rate=2e-4,
    batch_size=4,
    epochs=3,
    output_dir="./lora_model"
):
    """LoRA 微调完整实现"""
    
    # 1. 加载模型和分词器
    print(f"加载模型: {model_name}")
    model = AutoModelForCausalLM.from_pretrained(model_name)
    tokenizer = AutoTokenizer.from_pretrained(model_name)
    
    if tokenizer.pad_token is None:
        tokenizer.pad_token = tokenizer.eos_token
    
    # 2. 配置 LoRA
    print(f"配置 LoRA: rank={rank}, alpha={alpha}")
    lora_config = LoraConfig(
        task_type=TaskType.CAUSAL_LM,
        r=rank,                    # 低秩矩阵的秩
        lora_alpha=alpha,          # 缩放因子
        lora_dropout=dropout,      # Dropout
        target_modules=["c_attn"], # 目标层（GPT-2 的注意力层）
        bias="none",
    )
    
    # 3. 应用 LoRA
    model = get_peft_model(model, lora_config)
    
    # 打印可训练参数
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    total_params = sum(p.numel() for p in model.parameters())
    print(f"可训练参数: {trainable_params:,} ({trainable_params/total_params*100:.2f}%)")
    print(f"总参数: {total_params:,}")
    
    # 4. 训练参数
    training_args = TrainingArguments(
        output_dir=output_dir,
        num_train_epochs=epochs,
        per_device_train_batch_size=batch_size,
        gradient_accumulation_steps=4,
        learning_rate=learning_rate,
        warmup_steps=100,
        logging_steps=10,
        save_steps=500,
        fp16=True,                  # 混合精度训练
        save_total_limit=2,
        report_to="none",           # 不报告到 wandb/tensorboard
    )
    
    # 5. 训练
    trainer = Trainer(
        model=model,
        args=training_args,
        train_dataset=train_dataset,
    )
    
    print("开始训练...")
    trainer.train()
    
    # 6. 保存
    print(f"保存模型到: {output_dir}")
    model.save_pretrained(output_dir)
    tokenizer.save_pretrained(output_dir)
    
    return model, tokenizer

# 使用示例
if __name__ == "__main__":
    # 准备数据（假设已有 train_dataset）
    # train_dataset = prepare_and_format_dataset()
    
    # LoRA 微调
    model, tokenizer = lora_finetune(
        model_name="gpt2",
        train_dataset=train_dataset,
        rank=8,
        alpha=16,
        learning_rate=2e-4,
        batch_size=4,
        epochs=3,
    )
```

**参数对比**：
```
7B 参数的模型：

全量微调：
- 可训练参数：7B（100%）
- 显存需求：~28GB
- 训练时间：长

LoRA (rank=8)：
- 可训练参数：~10M（0.14%）
- 显存需求：~12GB
- 训练时间：短

节省：99.86% 参数！
```

---

### 3.3 QLoRA（量化 + LoRA）⭐ 显存受限推荐

**核心思想**：先用 4-bit 量化压缩模型，再用 LoRA 微调

**完整代码实现**：
```python
from transformers import BitsAndBytesConfig, AutoModelForCausalLM, AutoTokenizer
from transformers import TrainingArguments, Trainer
from peft import LoraConfig, get_peft_model, TaskType
import torch

def qlora_finetune(
    model_name="gpt2",
    train_dataset=None,
    rank=8,
    alpha=16,
    dropout=0.1,
    learning_rate=2e-4,
    batch_size=2,  # QLoRA 可以用更小的 batch
    epochs=3,
    output_dir="./qlora_model"
):
    """QLoRA 微调完整实现（4-bit 量化 + LoRA）"""
    
    # 1. 4-bit 量化配置
    print("配置 4-bit 量化...")
    bnb_config = BitsAndBytesConfig(
        load_in_4bit=True,                    # 4-bit 量化
        bnb_4bit_quant_type="nf4",           # 量化类型
        bnb_4bit_compute_dtype=torch.float16, # 计算精度
        bnb_4bit_use_double_quant=True,      # 双量化（更节省显存）
    )
    
    # 2. 加载量化模型
    print(f"加载量化模型: {model_name}")
    model = AutoModelForCausalLM.from_pretrained(
        model_name,
        quantization_config=bnb_config,
        device_map="auto",  # 自动分配设备
    )
    tokenizer = AutoTokenizer.from_pretrained(model_name)
    
    if tokenizer.pad_token is None:
        tokenizer.pad_token = tokenizer.eos_token
    
    # 3. LoRA 配置
    print(f"配置 LoRA: rank={rank}, alpha={alpha}")
    lora_config = LoraConfig(
        task_type=TaskType.CAUSAL_LM,
        r=rank,
        lora_alpha=alpha,
        lora_dropout=dropout,
        target_modules=["c_attn"],  # GPT-2
        bias="none",
    )
    
    # 4. 应用 LoRA
    model = get_peft_model(model, lora_config)
    
    # 打印可训练参数
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    total_params = sum(p.numel() for p in model.parameters())
    print(f"可训练参数: {trainable_params:,} ({trainable_params/total_params*100:.2f}%)")
    
    # 5. 训练参数
    training_args = TrainingArguments(
        output_dir=output_dir,
        num_train_epochs=epochs,
        per_device_train_batch_size=batch_size,
        gradient_accumulation_steps=8,  # 梯度累积
        learning_rate=learning_rate,
        warmup_steps=100,
        logging_steps=10,
        save_steps=500,
        fp16=True,
        save_total_limit=2,
        report_to="none",
    )
    
    # 6. 训练
    trainer = Trainer(
        model=model,
        args=training_args,
        train_dataset=train_dataset,
    )
    
    print("开始训练...")
    trainer.train()
    
    # 7. 保存
    print(f"保存模型到: {output_dir}")
    model.save_pretrained(output_dir)
    tokenizer.save_pretrained(output_dir)
    
    return model, tokenizer

# 使用示例
if __name__ == "__main__":
    # QLoRA 微调（显存需求低）
    model, tokenizer = qlora_finetune(
        model_name="gpt2",
        train_dataset=train_dataset,
        rank=8,
        alpha=16,
        learning_rate=2e-4,
        batch_size=2,
        epochs=3,
    )
```

**显存对比**：
```
7B 模型：
- 原始：~14GB
- 量化后：~4GB ✅
- 节省：约 70% 显存
```

---

## 4. 完整代码实现

### 4.1 端到端训练脚本

```python
"""
大模型训练完整脚本
包含：数据准备、LoRA微调、模型保存
"""

import os
import json
import torch
from datasets import Dataset, load_dataset
from transformers import (
    AutoModelForCausalLM,
    AutoTokenizer,
    TrainingArguments,
    Trainer,
    DataCollatorForLanguageModeling
)
from peft import LoraConfig, get_peft_model, TaskType

class ModelTrainer:
    """大模型训练器"""
    
    def __init__(self, model_name="gpt2"):
        self.model_name = model_name
        self.tokenizer = None
        self.model = None
    
    def prepare_dataset(self, data_path=None, dataset_name=None):
        """准备数据集"""
        print("=" * 50)
        print("准备数据集")
        print("=" * 50)
        
        # 方法1：从文件加载
        if data_path and os.path.exists(data_path):
            print(f"从文件加载: {data_path}")
            with open(data_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            dataset = Dataset.from_list(data)
        
        # 方法2：从 Hugging Face 加载
        elif dataset_name:
            print(f"从 Hugging Face 加载: {dataset_name}")
            dataset = load_dataset(dataset_name, split="train")
        
        # 方法3：使用示例数据
        else:
            print("使用示例数据")
            data = [
                {
                    "instruction": "解释什么是机器学习",
                    "input": "",
                    "output": "机器学习是人工智能的一个分支，通过算法让计算机从数据中学习..."
                },
                {
                    "instruction": "翻译成英文",
                    "input": "你好，世界",
                    "output": "Hello, World"
                },
            ]
            dataset = Dataset.from_list(data)
        
        print(f"数据集大小: {len(dataset)}")
        return dataset
    
    def format_dataset(self, dataset):
        """格式化数据集"""
        print("\n格式化数据集...")
        
        # 加载分词器
        self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)
        if self.tokenizer.pad_token is None:
            self.tokenizer.pad_token = self.tokenizer.eos_token
        
        def format_instruction(example):
            """格式化指令"""
            if "instruction" in example:
                text = f"### Instruction:\n{example['instruction']}\n"
                if example.get("input"):
                    text += f"### Input:\n{example['input']}\n"
                text += f"### Response:\n{example['output']}{self.tokenizer.eos_token}"
            else:
                text = example.get("text", "")
            return {"text": text}
        
        # 格式化
        formatted_dataset = dataset.map(format_instruction)
        
        # 分词
        def tokenize(examples):
            return self.tokenizer(
                examples["text"],
                truncation=True,
                max_length=512,
                padding="max_length",
            )
        
        tokenized_dataset = formatted_dataset.map(
            tokenize,
            batched=True,
            remove_columns=formatted_dataset.column_names,
        )
        
        print("格式化完成！")
        return tokenized_dataset
    
    def train_lora(
        self,
        train_dataset,
        rank=8,
        alpha=16,
        dropout=0.1,
        learning_rate=2e-4,
        batch_size=4,
        epochs=3,
        output_dir="./lora_model"
    ):
        """LoRA 微调"""
        print("\n" + "=" * 50)
        print("开始 LoRA 微调")
        print("=" * 50)
        
        # 1. 加载模型
        print(f"加载模型: {self.model_name}")
        self.model = AutoModelForCausalLM.from_pretrained(self.model_name)
        
        # 2. LoRA 配置
        print(f"LoRA 配置: rank={rank}, alpha={alpha}")
        lora_config = LoraConfig(
            task_type=TaskType.CAUSAL_LM,
            r=rank,
            lora_alpha=alpha,
            lora_dropout=dropout,
            target_modules=["c_attn"],  # GPT-2
            bias="none",
        )
        
        # 3. 应用 LoRA
        self.model = get_peft_model(self.model, lora_config)
        
        # 打印参数信息
        trainable = sum(p.numel() for p in self.model.parameters() if p.requires_grad)
        total = sum(p.numel() for p in self.model.parameters())
        print(f"可训练参数: {trainable:,} ({trainable/total*100:.2f}%)")
        print(f"总参数: {total:,}")
        
        # 4. 训练参数
        training_args = TrainingArguments(
            output_dir=output_dir,
            num_train_epochs=epochs,
            per_device_train_batch_size=batch_size,
            gradient_accumulation_steps=4,
            learning_rate=learning_rate,
            warmup_steps=100,
            logging_steps=10,
            save_steps=500,
            fp16=True,
            save_total_limit=2,
            report_to="none",
        )
        
        # 5. 数据整理器
        data_collator = DataCollatorForLanguageModeling(
            tokenizer=self.tokenizer,
            mlm=False,  # 因果语言模型，不是掩码语言模型
        )
        
        # 6. 训练器
        trainer = Trainer(
            model=self.model,
            args=training_args,
            train_dataset=train_dataset,
            data_collator=data_collator,
        )
        
        # 7. 训练
        print("\n开始训练...")
        trainer.train()
        
        # 8. 保存
        print(f"\n保存模型到: {output_dir}")
        self.model.save_pretrained(output_dir)
        self.tokenizer.save_pretrained(output_dir)
        
        print("训练完成！")
        return self.model, self.tokenizer
    
    def train_qlora(
        self,
        train_dataset,
        rank=8,
        alpha=16,
        dropout=0.1,
        learning_rate=2e-4,
        batch_size=2,
        epochs=3,
        output_dir="./qlora_model"
    ):
        """QLoRA 微调（4-bit 量化）"""
        print("\n" + "=" * 50)
        print("开始 QLoRA 微调（4-bit 量化）")
        print("=" * 50)
        
        from transformers import BitsAndBytesConfig
        
        # 1. 量化配置
        bnb_config = BitsAndBytesConfig(
            load_in_4bit=True,
            bnb_4bit_quant_type="nf4",
            bnb_4bit_compute_dtype=torch.float16,
            bnb_4bit_use_double_quant=True,
        )
        
        # 2. 加载量化模型
        print(f"加载量化模型: {self.model_name}")
        self.model = AutoModelForCausalLM.from_pretrained(
            self.model_name,
            quantization_config=bnb_config,
            device_map="auto",
        )
        self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)
        if self.tokenizer.pad_token is None:
            self.tokenizer.pad_token = self.tokenizer.eos_token
        
        # 3. LoRA 配置
        lora_config = LoraConfig(
            task_type=TaskType.CAUSAL_LM,
            r=rank,
            lora_alpha=alpha,
            lora_dropout=dropout,
            target_modules=["c_attn"],
            bias="none",
        )
        
        # 4. 应用 LoRA
        self.model = get_peft_model(self.model, lora_config)
        
        # 5-8. 训练和保存（同 LoRA）
        # ... (同上)
        
        return self.model, self.tokenizer
    
    def generate(self, prompt, max_length=100):
        """生成文本"""
        if self.model is None or self.tokenizer is None:
            raise ValueError("模型未加载，请先训练或加载模型")
        
        inputs = self.tokenizer(prompt, return_tensors="pt")
        outputs = self.model.generate(
            **inputs,
            max_length=max_length,
            temperature=0.7,
            do_sample=True,
        )
        
        generated_text = self.tokenizer.decode(outputs[0], skip_special_tokens=True)
        return generated_text

# 使用示例
if __name__ == "__main__":
    # 1. 创建训练器
    trainer = ModelTrainer(model_name="gpt2")
    
    # 2. 准备数据集
    dataset = trainer.prepare_dataset()
    
    # 3. 格式化数据集
    train_dataset = trainer.format_dataset(dataset)
    
    # 4. LoRA 微调
    model, tokenizer = trainer.train_lora(
        train_dataset=train_dataset,
        rank=8,
        alpha=16,
        learning_rate=2e-4,
        batch_size=4,
        epochs=3,
        output_dir="./my_lora_model"
    )
    
    # 5. 测试生成
    prompt = "### Instruction:\n解释什么是深度学习\n### Response:\n"
    result = trainer.generate(prompt)
    print("\n生成结果:")
    print(result)
```

---

## 5. 调参技巧与推荐配置

### 5.1 分场景推荐配置

#### 场景1：个人开发者（显存 < 10GB）

**推荐：QLoRA（量化 + LoRA）**

```python
RECOMMENDED_CONFIG_SMALL = {
    # LoRA 参数
    "rank": 8,
    "alpha": 16,
    "dropout": 0.1,
    "target_modules": ["q_proj", "v_proj"],
    
    # 训练参数
    "learning_rate": 2e-4,
    "batch_size": 2,
    "gradient_accumulation": 8,  # 实际 batch = 16
    "epochs": 3,
    "warmup_steps": 100,
    "max_length": 512,
    
    # 优化
    "fp16": True,
    "gradient_checkpointing": True,
}
```

**显存占用**：约 4-6GB  
**参数量**：约 0.1%（7B 模型约 10M 参数）

---

#### 场景2：有 GPU（显存 10-20GB）

**推荐：LoRA（标准）**

```python
RECOMMENDED_CONFIG_MEDIUM = {
    # LoRA 参数
    "rank": 16,
    "alpha": 32,
    "dropout": 0.1,
    "target_modules": ["q_proj", "k_proj", "v_proj", "o_proj"],
    
    # 训练参数
    "learning_rate": 3e-4,
    "batch_size": 4,
    "gradient_accumulation": 4,  # 实际 batch = 16
    "epochs": 3,
    "warmup_steps": 100,
    "max_length": 1024,
    
    # 优化
    "fp16": True,
}
```

**显存占用**：约 10-15GB  
**参数量**：约 0.3%（7B 模型约 20M 参数）

---

#### 场景3：有充足资源（显存 > 20GB）

**推荐：LoRA（增强版）或全量微调**

```python
RECOMMENDED_CONFIG_LARGE = {
    # LoRA 参数
    "rank": 32,
    "alpha": 64,
    "dropout": 0.05,
    "target_modules": [
        "q_proj", "k_proj", "v_proj", "o_proj",
        "gate_proj", "up_proj", "down_proj"  # 包含 FFN
    ],
    
    # 训练参数
    "learning_rate": 3e-4,
    "batch_size": 8,
    "gradient_accumulation": 2,  # 实际 batch = 16
    "epochs": 3,
    "warmup_steps": 200,
    "max_length": 2048,
    
    # 优化
    "fp16": True,
    "bf16": True,  # 如果 GPU 支持
}
```

**显存占用**：
- LoRA：约 15-20GB
- 全量微调：约 28GB（7B 模型）

---

### 5.2 参数调优方法

#### 方法1：网格搜索（Grid Search）

```python
import itertools

def grid_search(trainer, train_dataset):
    """网格搜索最佳参数"""
    
    # 定义搜索空间
    param_grid = {
        "rank": [4, 8, 16],
        "alpha": [8, 16, 32],
        "learning_rate": [1e-4, 2e-4, 3e-4],
        "batch_size": [2, 4, 8],
    }
    
    # 生成所有组合
    best_config = None
    best_score = float('inf')
    
    for rank, alpha, lr, bs in itertools.product(
        param_grid["rank"],
        param_grid["alpha"],
        param_grid["learning_rate"],
        param_grid["batch_size"]
    ):
        config = {
            "rank": rank,
            "alpha": alpha,
            "learning_rate": lr,
            "batch_size": bs
        }
        
        print(f"\n尝试配置: {config}")
        
        # 训练并评估
        try:
            model, tokenizer = trainer.train_lora(
                train_dataset=train_dataset,
                **config,
                epochs=1,  # 快速测试
            )
            
            # 评估（这里简化，实际需要验证集）
            score = evaluate_model(model, tokenizer)
            
            if score < best_score:
                best_score = score
                best_config = config
                print(f"新的最佳配置！Score: {score:.4f}")
        
        except Exception as e:
            print(f"配置失败: {e}")
            continue
    
    print(f"\n最佳配置: {best_config}")
    print(f"最佳得分: {best_score:.4f}")
    
    return best_config
```

---

#### 方法2：随机搜索（Random Search）

```python
import random
import numpy as np

def random_search(trainer, train_dataset, num_trials=20):
    """随机搜索最佳参数"""
    
    # 定义搜索空间
    param_space = {
        "rank": (4, 64),
        "alpha": (8, 128),
        "learning_rate": (1e-5, 5e-4),
        "batch_size": [2, 4, 8, 16],
    }
    
    best_config = None
    best_score = float('inf')
    
    for i in range(num_trials):
        # 随机采样
        config = {
            "rank": random.randint(param_space["rank"][0], param_space["rank"][1]),
            "alpha": random.randint(param_space["alpha"][0], param_space["alpha"][1]),
            "learning_rate": 10 ** random.uniform(
                np.log10(param_space["learning_rate"][0]),
                np.log10(param_space["learning_rate"][1])
            ),
            "batch_size": random.choice(param_space["batch_size"]),
        }
        
        # alpha 对齐到 rank
        config["alpha"] = (config["alpha"] // config["rank"]) * config["rank"]
        
        print(f"\n尝试 {i+1}/{num_trials}: {config}")
        
        try:
            model, tokenizer = trainer.train_lora(
                train_dataset=train_dataset,
                **config,
                epochs=1,
            )
            
            score = evaluate_model(model, tokenizer)
            
            if score < best_score:
                best_score = score
                best_config = config
                print(f"新的最佳配置！Score: {score:.4f}")
        
        except Exception as e:
            print(f"配置失败: {e}")
            continue
    
    return best_config, best_score
```

---

### 5.3 关键参数说明

#### Rank（低秩矩阵的秩）

```
简单任务（分类、QA）：
→ rank = 4-8

中等任务（摘要、对话）：
→ rank = 16-32

复杂任务（代码生成、长文本）：
→ rank = 32-64

注意：
- rank 越大，效果越好，但参数越多
- 通常从 8 开始尝试
```

#### Alpha（缩放因子）

```
通常规则：
alpha = rank × 2

例如：
rank = 8  → alpha = 16
rank = 16 → alpha = 32
rank = 32 → alpha = 64

也可以尝试：
alpha = rank（更保守）
alpha = rank × 4（更激进）
```

#### Learning Rate（学习率）

```
全量微调：
→ 1e-5 到 2e-5（较小）

LoRA 微调：
→ 1e-4 到 3e-4（可以稍大）

QLoRA：
→ 2e-4（推荐）

注意：
- 学习率太大 → 训练不稳定
- 学习率太小 → 训练太慢
```

#### Batch Size（批次大小）

```
显存充足：
→ batch_size = 8-16

显存中等：
→ batch_size = 4，gradient_accumulation = 4

显存受限：
→ batch_size = 2，gradient_accumulation = 8

实际 batch = batch_size × gradient_accumulation
```

---

### 5.4 常见问题解决

#### 问题1：显存不足

```python
# 解决方案
SOLUTION_OOM = {
    "batch_size": 1,              # 减小 batch
    "gradient_accumulation": 16,  # 增加累积步数
    "max_length": 256,            # 减小序列长度
    "fp16": True,                 # 使用混合精度
    "gradient_checkpointing": True,  # 梯度检查点
    # 或者使用 QLoRA（4-bit 量化）
    "use_qlora": True,
}
```

#### 问题2：训练不收敛

```python
# 解决方案
SOLUTION_NOT_CONVERGING = {
    "learning_rate": 1e-4,        # 减小学习率
    "warmup_steps": 500,          # 增加 warmup
    "rank": 16,                   # 增加 rank
    "alpha": 32,                  # 增加 alpha
    "epochs": 5,                  # 增加训练轮数
}
```

#### 问题3：过拟合

```python
# 解决方案
SOLUTION_OVERFITTING = {
    "dropout": 0.2,               # 增加 dropout
    "epochs": 1,                  # 减少训练轮数
    "learning_rate": 1e-4,        # 减小学习率
    "weight_decay": 0.01,         # 添加权重衰减
    "early_stopping": True,       # 早停
}
```

---

## 6. 实战案例

### 6.1 案例1：指令跟随模型训练

```python
"""
案例：训练一个指令跟随模型
任务：让模型能够理解和执行指令
"""

def case1_instruction_following():
    """案例1：指令跟随"""
    
    # 1. 创建训练器
    trainer = ModelTrainer(model_name="gpt2")
    
    # 2. 准备指令数据
    instruction_data = [
        {
            "instruction": "解释什么是机器学习",
            "input": "",
            "output": "机器学习是人工智能的一个分支，通过算法让计算机从数据中学习模式..."
        },
        {
            "instruction": "翻译成英文",
            "input": "你好，世界",
            "output": "Hello, World"
        },
        {
            "instruction": "总结以下文本",
            "input": "这是一段很长的文本...",
            "output": "总结：..."
        },
        # ... 更多数据
    ]
    
    # 保存数据
    with open("instruction_data.json", "w", encoding="utf-8") as f:
        json.dump(instruction_data, f, ensure_ascii=False, indent=2)
    
    # 3. 准备数据集
    dataset = trainer.prepare_dataset(data_path="instruction_data.json")
    train_dataset = trainer.format_dataset(dataset)
    
    # 4. 训练（使用推荐配置）
    model, tokenizer = trainer.train_lora(
        train_dataset=train_dataset,
        rank=8,
        alpha=16,
        learning_rate=2e-4,
        batch_size=4,
        epochs=3,
        output_dir="./instruction_model"
    )
    
    # 5. 测试
    prompt = "### Instruction:\n解释什么是深度学习\n### Response:\n"
    result = trainer.generate(prompt)
    print(result)
    
    return model, tokenizer

# 运行
# model, tokenizer = case1_instruction_following()
```

---

### 6.2 案例2：代码生成模型训练

```python
"""
案例：训练一个代码生成模型
任务：根据注释生成代码
"""

def case2_code_generation():
    """案例2：代码生成"""
    
    trainer = ModelTrainer(model_name="gpt2")
    
    # 代码数据
    code_data = [
        {
            "instruction": "生成一个Python函数",
            "input": "计算两个数的和",
            "output": "def add(a, b):\n    return a + b"
        },
        {
            "instruction": "生成一个Python函数",
            "input": "计算斐波那契数列",
            "output": "def fibonacci(n):\n    if n <= 1:\n        return n\n    return fibonacci(n-1) + fibonacci(n-2)"
        },
        # ... 更多代码数据
    ]
    
    # 准备和训练
    dataset = trainer.prepare_dataset()
    dataset = Dataset.from_list(code_data)
    train_dataset = trainer.format_dataset(dataset)
    
    # 训练（代码生成可能需要更大的 rank）
    model, tokenizer = trainer.train_lora(
        train_dataset=train_dataset,
        rank=16,  # 代码生成用更大的 rank
        alpha=32,
        learning_rate=2e-4,
        batch_size=4,
        epochs=3,
        output_dir="./code_model"
    )
    
    # 测试
    prompt = "### Instruction:\n生成一个Python函数\n### Input:\n计算列表的平均值\n### Response:\n"
    result = trainer.generate(prompt)
    print(result)
    
    return model, tokenizer
```

---

### 6.3 案例3：对话模型训练（显存受限）

```python
"""
案例：在显存受限的情况下训练对话模型
使用 QLoRA（4-bit 量化）
"""

def case3_chat_model_low_memory():
    """案例3：低显存对话模型"""
    
    trainer = ModelTrainer(model_name="gpt2")
    
    # 对话数据
    chat_data = [
        {
            "conversations": [
                {"role": "user", "content": "你好"},
                {"role": "assistant", "content": "你好！有什么可以帮助你的吗？"}
            ]
        },
        {
            "conversations": [
                {"role": "user", "content": "什么是AI？"},
                {"role": "assistant", "content": "AI是人工智能的缩写..."}
            ]
        },
        # ... 更多对话
    ]
    
    # 转换为指令格式
    instruction_data = []
    for item in chat_data:
        user_msg = item["conversations"][0]["content"]
        assistant_msg = item["conversations"][1]["content"]
        instruction_data.append({
            "instruction": "回答用户的问题",
            "input": user_msg,
            "output": assistant_msg
        })
    
    # 准备数据集
    dataset = Dataset.from_list(instruction_data)
    train_dataset = trainer.format_dataset(dataset)
    
    # 使用 QLoRA（节省显存）
    model, tokenizer = trainer.train_qlora(
        train_dataset=train_dataset,
        rank=8,
        alpha=16,
        learning_rate=2e-4,
        batch_size=2,  # 小 batch
        epochs=3,
        output_dir="./chat_model_qlora"
    )
    
    return model, tokenizer
```

---

## 7. 完整训练流程总结

### 7.1 标准流程

```
1. 确定任务类型
   ↓
2. 准备数据集（格式、数量）
   ↓
3. 选择训练方法（LoRA/QLoRA/全量微调）
   ↓
4. 配置参数（rank, alpha, learning_rate等）
   ↓
5. 开始训练
   ↓
6. 监控训练过程（loss、显存等）
   ↓
7. 评估模型效果
   ↓
8. 调参优化（如果需要）
   ↓
9. 保存最终模型
```

### 7.2 快速开始模板

```python
"""
快速开始模板
复制这个模板，修改数据路径和参数即可开始训练
"""

from model_trainer import ModelTrainer

# 1. 创建训练器
trainer = ModelTrainer(model_name="gpt2")  # 或 "gpt2-medium", "gpt2-large"

# 2. 准备数据（选择一种方式）
# 方式A：从文件加载
dataset = trainer.prepare_dataset(data_path="your_data.json")

# 方式B：从 Hugging Face 加载
# dataset = trainer.prepare_dataset(dataset_name="tatsu-lab/alpaca")

# 方式C：使用示例数据
# dataset = trainer.prepare_dataset()

# 3. 格式化数据
train_dataset = trainer.format_dataset(dataset)

# 4. 训练（选择一种方法）
# 方法A：LoRA（推荐，显存 10-20GB）
model, tokenizer = trainer.train_lora(
    train_dataset=train_dataset,
    rank=8,
    alpha=16,
    learning_rate=2e-4,
    batch_size=4,
    epochs=3,
    output_dir="./my_model"
)

# 方法B：QLoRA（显存受限，<10GB）
# model, tokenizer = trainer.train_qlora(
#     train_dataset=train_dataset,
#     rank=8,
#     alpha=16,
#     learning_rate=2e-4,
#     batch_size=2,
#     epochs=3,
#     output_dir="./my_model"
# )

# 5. 测试
prompt = "### Instruction:\n你的问题\n### Response:\n"
result = trainer.generate(prompt)
print(result)
```

---

## 8. 安装依赖

### 8.1 必需库

```bash
# 基础库
pip install torch transformers datasets

# LoRA 支持
pip install peft

# QLoRA 支持（4-bit 量化）
pip install bitsandbytes accelerate

# 可选：训练监控
pip install wandb tensorboard
```

### 8.2 完整安装命令

```bash
pip install torch transformers datasets peft bitsandbytes accelerate
```

---

## 9. 常见错误和解决方案

### 错误1：CUDA out of memory

```
错误：RuntimeError: CUDA out of memory

解决方案：
1. 减小 batch_size
2. 增加 gradient_accumulation_steps
3. 减小 max_length
4. 使用 QLoRA（4-bit 量化）
5. 使用 gradient_checkpointing
```

### 错误2：找不到 target_modules

```
错误：ValueError: Target modules not found

解决方案：
检查模型结构，找到正确的模块名：
- GPT-2: ["c_attn"]
- LLaMA: ["q_proj", "v_proj"]
- BERT: ["query", "value"]
```

### 错误3：训练 loss 不下降

```
问题：训练 loss 不下降或上升

解决方案：
1. 减小学习率（如 1e-4）
2. 增加 warmup_steps
3. 检查数据质量
4. 增加 rank（如 16）
5. 检查数据格式是否正确
```

---

## 10. 总结

### 10.1 核心要点

1. **数据集是必需的**
   - 没有数据无法训练
   - 数据质量决定模型效果
   - LoRA 只需要少量数据（1000-10000 样本）

2. **LoRA 是最实用的方法**
   - 只需训练 0.1-1% 的参数
   - 显存需求低（10-15GB）
   - 效果接近全量微调

3. **QLoRA 适合显存受限**
   - 4-bit 量化节省 70% 显存
   - 只需 4-6GB 显存
   - 效果仍然很好

4. **参数调优很重要**
   - rank: 8-32（根据任务复杂度）
   - alpha: rank × 2
   - learning_rate: 1e-4 到 3e-4

### 10.2 推荐配置速查表

| 场景 | 方法 | Rank | Alpha | LR | Batch | 显存 |
|------|------|------|-------|----|----|------|
| **显存受限** | QLoRA | 8 | 16 | 2e-4 | 2 | 4-6GB |
| **标准配置** | LoRA | 16 | 32 | 3e-4 | 4 | 10-15GB |
| **效果优先** | LoRA | 32 | 64 | 3e-4 | 8 | 15-20GB |
| **资源充足** | 全量微调 | - | - | 2e-5 | 4 | 28GB+ |

### 10.3 下一步

1. ✅ 准备你的数据集
2. ✅ 选择合适的训练方法
3. ✅ 使用推荐配置开始训练
4. ✅ 根据效果调参优化
5. ✅ 保存和部署模型

---

**文档版本**: v1.0  
**最后更新**: 2026-01-09  
**内容**：大模型训练与参数调优完整指南（包含完整代码）

